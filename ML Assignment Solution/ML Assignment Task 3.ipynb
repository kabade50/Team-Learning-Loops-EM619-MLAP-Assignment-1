{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n",
      "  Downloading langchain_core-0.3.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.26.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.35->langchain)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (2.1)\n",
      "Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.0 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.0/1.0 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.40-py3-none-any.whl (414 kB)\n",
      "   ---------------------------------------- 0.0/414.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 414.3/414.3 kB 13.0 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.11-py3-none-any.whl (335 kB)\n",
      "   ---------------------------------------- 0.0/335.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 335.3/335.3 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 431.7/431.7 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.8/2.0 MB 37.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 31.9 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.15-cp312-cp312-win_amd64.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 7.7 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "   ---------------------------------------- 0.0/495.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 495.6/495.6 kB 32.4 MB/s eta 0:00:00\n",
      "Installing collected packages: zstandard, typing-extensions, orjson, pydantic-core, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.22.0\n",
      "    Uninstalling zstandard-0.22.0:\n",
      "      Successfully uninstalled zstandard-0.22.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed langchain-0.3.19 langchain-core-0.3.40 langchain-text-splitters-0.3.6 langsmith-0.3.11 orjson-3.10.15 pydantic-2.10.6 pydantic-core-2.27.2 typing-extensions-4.12.2 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
      "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain_groq) (0.3.40)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (0.3.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (23.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.2.2)\n",
      "Downloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
      "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.9 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 112.6/121.9 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 121.9/121.9 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: groq, langchain_groq\n",
      "Successfully installed groq-0.18.0 langchain_groq-0.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models \n",
    "Groq_Token = \"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\"  # Do not share this key with anyone\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.**\n",
    "\n",
    "Always do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 0.5 marks deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Label: Neutral\n",
      "\n",
      "Explanation: The sentence expresses mixed sentiments. The words \"amazing\" and \"happy\" convey a positive sentiment, indicating satisfaction with the product quality and customer service. However, the phrase \"delivery was delayed\" expresses a negative sentiment, indicating dissatisfaction with the delivery experience. Overall, the positive and negative sentiments balance each other out, resulting in a neutral sentiment label.\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n",
      "\n",
      "Explanation: Although the sentence mentions a negative aspect (\"the delivery was delayed\"), the positive sentiments expressed in the sentence (\"The product quality is amazing\" and \"I am happy with the customer service\") outweigh the negative one, resulting in an overall positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are few examples:\n",
    "1. Sentence: 'The customer service was excellent, and I received my order quickly.'\n",
    "Sentiment: Positive\n",
    "\n",
    "2. Sentence: 'The food was bland and the service was slow.'\n",
    "Sentiment: Negative\n",
    "\n",
    "3. Sentence: 'The product is okay, but it's not worth the price.'\n",
    "Sentiment: Neutral\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = groq.Groq(api_key=\"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\")\n",
    "\n",
    "def zero_shot_classification(feature_description):\n",
    "    prompt = f\"\"\"\n",
    "    Based on the provided signal characteristics, is this more likely to be one of the following activities:\n",
    "    LAYING, SITTING, STANDING, WALKING, WALKING_DOWNSTAIRS, or WALKING_UPSTAIRS?\n",
    "    \n",
    "    Features: {feature_description}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a human activity classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def few_shot_classification(feature_description, examples):\n",
    "    example_text = \"\\n\".join([f\"{desc} → {label}\" for desc, label in examples])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Here are some examples of activity features and their corresponding labels:\n",
    "    {example_text}\n",
    "\n",
    "    Now, given the new sample ({feature_description}), what is the most likely activity?\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a human activity classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3\n",
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Prediction: Based on the provided signal characteristics, I would classify this activity as WALKING. The moderate mean suggests a movement with a reasonable level of intensity, which is consistent with walking. The high variance indicates a dynamic signal with varying frequencies, which is also consistent with walking. The presence of frequency peaks suggests that the signal has some periodic components, which could be related to the rhythmic motion of walking. While it's possible that this signal could also be related to other activities, such as walking downstairs, the overall pattern is more consistent with walking.\n",
      "Few-Shot Prediction: Based on the given features, I would classify the activity as WALKING.\n",
      "\n",
      "Here's how the features match with the examples:\n",
      "\n",
      "* Mean: moderate → This falls within the range of walking (moderate speed), unlike the other examples (low for sitting and high for laying).\n",
      "* Variance: high → This is similar to WALKING, which is a high-variability activity.\n",
      "* Some frequency peaks → This is also consistent with WALKING, as walking is a relatively irregular activity with fluctuating frequencies.\n",
      "\n",
      "Given the combination of moderate mean, high variance, and the presence of frequency peaks, WALKING appears to be the most likely activity.\n",
      "\n",
      "Comparison:\n",
      "Zero-Shot Learning (ZSL): Works without prior examples but may misclassify subtle differences.\n",
      "Few-Shot Learning (FSL): Uses examples for better pattern recognition, leading to higher accuracy.\n"
     ]
    }
   ],
   "source": [
    "import groq\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = groq.Groq(api_key=\"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\")\n",
    "\n",
    "def zero_shot_classification(feature_description):\n",
    "    prompt = f\"\"\"\n",
    "    Based on the provided signal characteristics, is this more likely to be one of the following activities:\n",
    "    LAYING, SITTING, STANDING, WALKING, WALKING_DOWNSTAIRS, or WALKING_UPSTAIRS?\n",
    "    \n",
    "    Features: {feature_description}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a human activity classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def few_shot_classification(feature_description, examples):\n",
    "    example_text = \"\\n\".join([f\"{desc} → {label}\" for desc, label in examples])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Here are some examples of activity features and their corresponding labels:\n",
    "    {example_text}\n",
    "\n",
    "    Now, given the new sample ({feature_description}), what is the most likely activity?\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a human activity classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example Feature Descriptions for Testing\n",
    "feature_description = \"Mean: moderate, Variance: high, Some frequency peaks\"\n",
    "\n",
    "# Few-shot examples: (Feature Description, Corresponding Label)\n",
    "examples = [\n",
    "    (\"Mean: low, Variance: high, Frequency peaks: regular\", \"WALKING\"),\n",
    "    (\"Mean: moderate, Variance: low, No frequency peaks\", \"SITTING\"),\n",
    "    (\"Mean: high, Variance: low, Flat signal\", \"LAYING\")\n",
    "]\n",
    "\n",
    "# Zero-Shot Classification\n",
    "zsl_result = zero_shot_classification(feature_description)\n",
    "print(\"Zero-Shot Prediction:\", zsl_result)\n",
    "\n",
    "# Few-Shot Classification\n",
    "fsl_result = few_shot_classification(feature_description, examples)\n",
    "print(\"Few-Shot Prediction:\", fsl_result)\n",
    "\n",
    "# Qualitative Comparison\n",
    "print(\"\\nComparison:\")\n",
    "print(\"Zero-Shot Learning (ZSL): Works without prior examples but may misclassify subtle differences.\")\n",
    "print(\"Few-Shot Learning (FSL): Uses examples for better pattern recognition, leading to higher accuracy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3\n",
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot Prediction: Based on the features you provided, I would say that this signal is more likely to be WALKING. Here's why:\n",
      "\n",
      "* Mean: moderate - Walking typically has a moderate level of activity, which is consistent with a moderate mean value.\n",
      "* Variance: high - Walking typically has a high level of variance, as the activity is dynamic and involves a range of movements. This high variance is also consistent with the high value.\n",
      "* Some frequency peaks - Walking often has frequency peaks in the range of 1-3 Hz, which is consistent with the presence of some frequency peaks.\n",
      "\n",
      "While the signal could potentially be WALKING_UPSTAIRS, the lack of extremely high frequency peaks (>4 Hz) suggests that this may not be the case. LAYING and SITTING typically have lower variances and no frequency peaks, so these activities are less likely. STANDING is also unlikely due to the high variance. WALKING_DOWNSTAIRS is also possible, but based on the frequency peaks, I would still lean towards WALKING being the most likely activity.\n",
      "Few-Shot Prediction: Based on the given features and their corresponding labels, I would classify the most likely activity as STANDING.\n",
      "\n",
      "Here's the reasoning:\n",
      "\n",
      "* Mean: moderate suggests the activity is not extremely low (sitting) or extremely high (running), which leaves standing as a possibility.\n",
      "* Variance: high suggests some movement or variation in the signal, which is consistent with standing as it implies some movement or bouncing.\n",
      "* Frequency peaks: some suggests some periodicity, which is consistent with standing, as standing motion involves occasional and irregular movements, which can result in varying frequency peaks.\n",
      "\n",
      "So, given these features, I would classify the most likely activity as STANDING.\n",
      "Decision Tree Prediction: WALKING\n",
      "Decision Tree Accuracy: 1.0\n",
      "\n",
      "Comparison:\n",
      "Zero-Shot Learning (ZSL): Works without prior examples but may misclassify subtle differences.\n",
      "Few-Shot Learning (FSL): Uses examples for better pattern recognition, leading to higher accuracy.\n",
      "Decision Trees (DT): Learns from structured data and achieves high accuracy with enough training samples.\n"
     ]
    }
   ],
   "source": [
    "import groq\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = groq.Groq(api_key=\"your-api-key\")\n",
    "\n",
    "def zero_shot_classification(feature_description):\n",
    "    prompt = f\"\"\"\n",
    "    Based on the provided signal characteristics, is this more likely to be one of the following activities:\n",
    "    LAYING, SITTING, STANDING, WALKING, WALKING_DOWNSTAIRS, or WALKING_UPSTAIRS?\n",
    "    \n",
    "    Features: {feature_description}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a human activity classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def few_shot_classification(feature_description, examples):\n",
    "    example_text = \"\\n\".join([f\"{desc} → {label}\" for desc, label in examples])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Here are some examples of activity features and their corresponding labels:\n",
    "    {example_text}\n",
    "\n",
    "    Now, given the new sample ({feature_description}), what is the most likely activity?\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama3-8b-8192\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a human activity classifier.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example Feature Descriptions for Testing\n",
    "feature_description = \"Mean: moderate, Variance: high, Some frequency peaks\"\n",
    "\n",
    "# Few-shot examples: (Feature Description, Corresponding Label)\n",
    "examples = [\n",
    "    (\"Mean: low, Variance: high, Frequency peaks: regular\", \"WALKING\"),\n",
    "    (\"Mean: moderate, Variance: low, No frequency peaks\", \"SITTING\"),\n",
    "    (\"Mean: high, Variance: low, Flat signal\", \"LAYING\")\n",
    "]\n",
    "\n",
    "# Zero-Shot Classification\n",
    "zsl_result = zero_shot_classification(feature_description)\n",
    "print(\"Zero-Shot Prediction:\", zsl_result)\n",
    "\n",
    "# Few-Shot Classification\n",
    "fsl_result = few_shot_classification(feature_description, examples)\n",
    "print(\"Few-Shot Prediction:\", fsl_result)\n",
    "\n",
    "# Decision Tree Classification (Using Sample Data)\n",
    "X_train = np.array([\n",
    "    [0.2, 0.8, 1],  # WALKING\n",
    "    [0.5, 0.2, 0],  # SITTING\n",
    "    [0.9, 0.1, 0]   # LAYING\n",
    "])\n",
    "y_train = np.array([\"WALKING\", \"SITTING\", \"LAYING\"])\n",
    "\n",
    "X_test = np.array([\n",
    "    [0.4, 0.7, 1]  # Test Sample Similar to WALKING\n",
    "])\n",
    "y_test = np.array([\"WALKING\"])\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Decision Tree Prediction:\", y_pred[0])\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "\n",
    "# Qualitative & Quantitative Comparison\n",
    "print(\"\\nComparison:\")\n",
    "print(\"Zero-Shot Learning (ZSL): Works without prior examples but may misclassify subtle differences.\")\n",
    "print(\"Few-Shot Learning (FSL): Uses examples for better pattern recognition, leading to higher accuracy.\")\n",
    "print(\"Decision Trees (DT): Learns from structured data and achieves high accuracy with enough training samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3\n",
    "Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Limitations of Zero-Shot and Few-Shot Learning in Classifying Human Activities\n",
    "\n",
    "Zero-Shot Learning (ZSL) Limitations:\n",
    "1. Lack of Context-Specific Knowledge->\n",
    "\n",
    "Since ZSL relies solely on general language understanding, it may not interpret accelerometer features accurately, leading to misclassification.\n",
    "\n",
    "2.Difficulty in Recognizing Subtle Differences\n",
    "\n",
    "ZSL struggles to differentiate between activities with similar feature distributions, e.g., STANDING vs. SITTING or WALKING vs. WALKING_UPSTAIRS.\n",
    "\n",
    "3.No Adaptation to Sensor-Specific Variability\n",
    "\n",
    "Sensor data varies across devices and individuals, but ZSL cannot adapt without additional training data.\n",
    "\n",
    "4.Inconsistent Outputs\n",
    "\n",
    "The model may generate different predictions for similar inputs due to the probabilistic nature of large language models.\n",
    "\n",
    "Few-Shot Learning (FSL) Limitations:\n",
    "\n",
    "1.Limited by the Quality of Examples\n",
    "\n",
    "If the provided few-shot examples do not adequately cover variations in activity patterns, the model may generalize poorly.\n",
    "\n",
    "2.Still Prone to Ambiguity\n",
    "\n",
    "While better than ZSL, FSL can still struggle with overlapping classes, especially when feature descriptions are vague.\n",
    "\n",
    "3.Not as Data-Efficient as Traditional Models\n",
    "\n",
    "Compared to a trained Decision Tree or other ML models, FSL does not optimize decision boundaries efficiently and might require more examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
